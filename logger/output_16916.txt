tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')
tensor([[   105,   1537,   2602,    351,   1313,    759,    354,   9886,    258,
         115913,    296,    258,    258,    561,  12118,  44924,   2961,    941,
         106312,    926,    569,    265,  74650,   2465, 144620, 131023,    941,
          74672,    296,  26046,   3048,  10581,    566,   1313,    371,  13446,
            564,    258,    258,   2204,    258,  80641,    757, 106208,    569,
            699,   2961,   2269,    258,   1366,    258,  52632,    798,    875,
          86116,   2205,    956,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259]], device='cuda:0')
Logits shape = torch.Size([1, 256, 150000])
Before BERT:
tensor([[   105,   1537,   2602,    351,   1313,    759,    354,   9886,    258,
         115913,    296,    258,    258,    561,  12118,  44924,   2961,    941,
         106312,    926,    569,    265,  74650,   2465, 144620, 131023,    941,
          74672,    296,  26046,   3048,  10581,    566,   1313,    371,  13446,
            564,    258,    258,   2204,    258,  80641,    757, 106208,    569,
            699,   2961,   2269,    258,   1366,    258,  52632,    798,    875,
          86116,   2205,    956,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259,    259,    259,    259,    259,    259,
            259,    259,    259,    259]], device='cuda:0')
["i think most of us have that crisis<MASK> discovering the<MASK><MASK> any religious book, is not literal or in a child's understanding, not real. the metaphors are lost on us as children and<MASK><MASK> we've<MASK> cheated into believing in what is nothing<MASK> than<MASK> grown up's fairy tale.<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>"]
After BERT:
tensor([[   105,    356,   2460,    575,  11705,    356,   2512,  58393,    296,
            970,    575,    296,    296,    542,    621,    264,    575,    575,
           2460,   2482,   2460,    575,    281, 114103,    116,  58393,    575,
         112319,    575,    520, 100737,     98,  58393,  11705,    575,   2460,
            520,    296,    296,    520,    296,  38476,    105,    356,   2460,
            277,    575,    365,    296,  22333,    296,    264,   2512,    875,
            520,    116,   2460,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575,    575,    575,    575,    575,    575,
            575,    575,    575,    575]], device='cuda:0')
["iweby wesomewepebut thether we the thesoliin we webyshby wesewell,tbut weeve wefrommybbutsome webyfrom the thefrom thethaniweby to wego thewell theinpe'sfromtby we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we"]
